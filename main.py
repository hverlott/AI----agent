import asyncio
import os
import sys
import shutil
import random
import json
import re
import uuid
import difflib
from datetime import datetime
import httpx # å¿…é¡»ç¡®ä¿å·²å®‰è£…: pip install httpx
from telethon import TelegramClient, events
from openai import AsyncOpenAI, APIConnectionError
from dotenv import load_dotenv

# --- Auto-setup Environment ---
# If .env is missing, try to create it from .env.example
_env_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '.env')
_env_example_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '.env.example')
if not os.path.exists(_env_path) and os.path.exists(_env_example_path):
    try:
        shutil.copy(_env_example_path, _env_path)
        print(f"âš ï¸ æ£€æµ‹åˆ° .env ç¼ºå¤±ï¼Œå·²æ ¹æ® .env.example è‡ªåŠ¨ç”Ÿæˆ: {_env_path}")
    except Exception as e:
        print(f"âŒ æ— æ³•è‡ªåŠ¨ç”Ÿæˆ .env: {e}")

load_dotenv()

# --- Env Validation ---
if not os.getenv('TELEGRAM_API_ID'):
    print("================================================================")
    print("âŒ é”™è¯¯: æœªæ£€æµ‹åˆ° TELEGRAM_API_ID")
    print("âš ï¸ è¯·æ‰“å¼€ .env æ–‡ä»¶ï¼Œå¡«å†™æ‚¨çš„ Telegram API é…ç½®å’Œ AI å¯†é’¥")
    print("================================================================")
    sys.exit(1)

from database import db
from audit_manager import AuditManager
from conversation_state_manager import ConversationStateManager
from supervisor_agent import SupervisorAgent
from stage_agent_runtime import StageAgentRuntime

# --- 1. åŸºç¡€è®¾ç½® ---
# è§£å†³ Windows æ§åˆ¶å°ä¹±ç 
if sys.platform == 'win32':
    try:
        import codecs
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except:
        pass

load_dotenv()

def _ssl_verify_default():
    v = (os.getenv("HTTPX_VERIFY_SSL") or "").strip().lower()
    if v in ("0", "false", "no"):
        return False
    return True

# --- Logging (system / private / group) ---
LOG_DIR = os.path.join("platforms", "telegram", "logs")
SYSTEM_LOG_FILE = os.path.join(LOG_DIR, "system.log")
PRIVATE_LOG_FILE = os.path.join(LOG_DIR, "private.log")
GROUP_LOG_FILE = os.path.join(LOG_DIR, "group.log")
TRACE_LOG_FILE = os.path.join(LOG_DIR, "trace.jsonl")

def _append_log(file_path, message):
    os.makedirs(os.path.dirname(file_path), exist_ok=True)
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open(file_path, "a", encoding="utf-8") as f:
        f.write(f"[{ts}] {message}\n")

def log_trace_event(trace_id, event_type, payload):
    """
    è®°å½•ç»“æ„åŒ–è¿½è¸ªæ—¥å¿— (JSONL æ ¼å¼)
    ç¬¦åˆ Automated Acceptance Execution Checklist è¦æ±‚
    """
    os.makedirs(os.path.dirname(TRACE_LOG_FILE), exist_ok=True)
    
    # æ„é€ æ ‡å‡†äº‹ä»¶ç»“æ„
    event = {
        "trace_id": trace_id,
        "timestamp": datetime.now().isoformat(),
        "event_type": event_type
    }
    # åˆå¹¶ payload
    event.update(payload)
    
    with open(TRACE_LOG_FILE, "a", encoding="utf-8") as f:
        f.write(json.dumps(event, ensure_ascii=False) + "\n")

def log_system(message):
    _append_log(SYSTEM_LOG_FILE, message)
    print(message)

def log_private(message):
    _append_log(PRIVATE_LOG_FILE, message)
    print(message)

def log_group(message):
    _append_log(GROUP_LOG_FILE, message)
    print(message)

# --- 2. åŠ è½½é…ç½® & è‡ªåŠ¨ä¿®å¤é”™è¯¯ ---
TELEGRAM_API_ID = os.getenv('TELEGRAM_API_ID')
TELEGRAM_API_HASH = os.getenv('TELEGRAM_API_HASH')
AI_API_KEY = os.getenv('AI_API_KEY')
AI_BASE_URL = os.getenv('AI_BASE_URL')
AI_MODEL_NAME = os.getenv('AI_MODEL_NAME')

# ğŸ”ã€è‡ªåŠ¨ä¿®å¤åŠŸèƒ½ã€‘é˜²æ­¢ .env å¡«é”™
if AI_BASE_URL:
    # 1. å¦‚æœå¿˜äº†å†™ https://ï¼Œè‡ªåŠ¨è¡¥ä¸Š
    if not AI_BASE_URL.startswith("http"):
        AI_BASE_URL = f"https://{AI_BASE_URL}"
    
    # 2. ã€å…³é”®ä¿®å¤ã€‘å°†é”™è¯¯åŸŸå 55.ai æ›¿æ¢ä¸ºæ­£ç¡®çš„ api.55.ai
    if "://55.ai" in AI_BASE_URL:
        AI_BASE_URL = AI_BASE_URL.replace("://55.ai", "://api.55.ai")
        log_system("âš ï¸ æ£€æµ‹åˆ°æ—§åŸŸåï¼Œå·²è‡ªåŠ¨ä¿®æ­£ä¸º api.55.ai")
    
    # 3. å¦‚æœå¤šå†™äº† /chat/completionsï¼Œè‡ªåŠ¨å»æ‰ï¼ˆOpenAI SDK ä¼šè‡ªåŠ¨æ‹¼æ¥ï¼‰
    if "/chat/completions" in AI_BASE_URL:
        AI_BASE_URL = AI_BASE_URL.replace("/chat/completions", "")
    
    # 4. ç¡®ä¿ä»¥ /v1 ç»“å°¾ï¼ˆæ ¹æ® API è§„èŒƒï¼‰
    if not AI_BASE_URL.endswith("/v1"):
        AI_BASE_URL = AI_BASE_URL.rstrip("/") + "/v1"

log_system(f"ğŸ”§ AI æ¥å£åœ°å€å·²ä¿®æ­£ä¸º: {AI_BASE_URL}")

# --- 3. åˆå§‹åŒ–å®¢æˆ·ç«¯ (æŠ—å¹²æ‰°æ¨¡å¼) ---

# åˆ›å»ºå®¢æˆ·ç«¯çš„æƒ°æ€§åˆå§‹åŒ–ï¼Œé¿å…åœ¨è¢«å…¶ä»–çº¿ç¨‹å¯¼å…¥æ—¶ç¼ºå¤±äº‹ä»¶å¾ªç¯
http_client = None
ai_client = None

def get_ai_client():
    global http_client, ai_client
    if ai_client is None or http_client is None:
        ssl_mode = _ssl_verify_default()
        log_system(f"ğŸ”Œ åˆå§‹åŒ– AI å®¢æˆ·ç«¯: SSLéªŒè¯={ssl_mode}")
        http_client = httpx.AsyncClient(verify=ssl_mode, timeout=30.0)
        ai_client = AsyncOpenAI(
            api_key=AI_API_KEY,
            base_url=AI_BASE_URL,
            http_client=http_client
        )
    return ai_client

def reset_ai_client():
    global http_client, ai_client
    http_client = None
    ai_client = None
    log_system("ğŸ”„ AI å®¢æˆ·ç«¯å·²é‡ç½® (å‡†å¤‡é‡æ–°åˆå§‹åŒ–)")

client = TelegramClient('userbot_session', int(TELEGRAM_API_ID), TELEGRAM_API_HASH)

# ã€å·²ç§»é™¤ç¡¬ç¼–ç ã€‘ç°åœ¨æç¤ºè¯ä» prompt.txt æ–‡ä»¶åŠ¨æ€åŠ è½½
# SYSTEM_PROMPT = """..."""

# --- 4. æ ¸å¿ƒé€»è¾‘ ---

def load_system_prompt():
    """
    çƒ­æ›´æ–°åŠŸèƒ½ï¼šä» prompt.txt è¯»å– AI æç¤ºè¯
    è¿™æ ·å¯ä»¥åœ¨ç¨‹åºè¿è¡Œæ—¶éšæ—¶ä¿®æ”¹ AI äººè®¾ï¼Œæ— éœ€é‡å¯
    """
    prompt_file = "platforms/telegram/prompt.txt"
    default_prompt = "ä½ æ˜¯ä¸€ä¸ªå¹½é»˜ã€ä¸“ä¸šçš„ä¸ªäººåŠ©ç†ï¼Œå¸®æœºä¸»å›å¤æ¶ˆæ¯ã€‚è¯·ç”¨è‡ªç„¶ã€å‹å¥½çš„è¯­æ°”å›å¤ã€‚"
    
    try:
        with open(prompt_file, 'r', encoding='utf-8') as f:
            content = f.read().strip()
            if content:
                return content
            else:
                return default_prompt
    except FileNotFoundError:
        log_system(f"âš ï¸ æœªæ‰¾åˆ° {prompt_file}ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
        return default_prompt
    except Exception as e:
        log_system(f"âš ï¸ è¯»å– {prompt_file} å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
        return default_prompt

def load_keywords():
    """
    çƒ­æ›´æ–°åŠŸèƒ½ï¼šä» keywords.txt è¯»å–ç¾¤èŠè§¦å‘å…³é”®è¯
    æ¯æ¬¡å¤„ç†æ¶ˆæ¯æ—¶é‡æ–°è¯»å–ï¼Œå®ç°å®æ—¶æ›´æ–°
    """
    keywords_file = "platforms/telegram/keywords.txt"
    keywords = []
    
    try:
        with open(keywords_file, 'r', encoding='utf-8') as f:
            for line in f:
                keyword = line.strip()
                # å¿½ç•¥ç©ºè¡Œå’Œæ³¨é‡Šè¡Œï¼ˆä»¥ # å¼€å¤´ï¼‰
                if keyword and not keyword.startswith('#'):
                    keywords.append(keyword)
        return keywords
    except FileNotFoundError:
        # æ–‡ä»¶ä¸å­˜åœ¨æ—¶è¿”å›ç©ºåˆ—è¡¨ï¼ˆç¾¤èŠåªèƒ½é€šè¿‡ @ è§¦å‘ï¼‰
        return []
    except Exception as e:
        log_system(f"âš ï¸ è¯»å– {keywords_file} å¤±è´¥: {e}")
        return []


# ===== Q&A Knowledge Base (Telegram) =====
def _read_lines_with_fallback(file_path):
    encodings = ["utf-8", "gbk", "cp936"]
    for enc in encodings:
        try:
            with open(file_path, "r", encoding=enc) as f:
                return f.read().splitlines()
        except UnicodeDecodeError:
            continue
    with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
        return f.read().splitlines()

def _split_variants(text):
    parts = re.split(r"[\\/|ï½œ]+", text)
    return [p.strip() for p in parts if p.strip()]

def load_qa_pairs(file_path):
    qa_pairs = []
    if not file_path or (not os.path.exists(file_path)):
        return qa_pairs
    try:
        raw_lines = _read_lines_with_fallback(file_path)
        pending_qs = []
        collecting = False
        answer_lines = []
        for line in raw_lines:
            stripped = line.strip()
            if not stripped:
                if collecting and pending_qs:
                    answer_lines.append("")
                continue
            if stripped.startswith('#'):
                continue
            if '||' in stripped:
                q, a = stripped.split('||', 1)
                q = q.strip()
                a = a.strip()
                if q and a:
                    variants = _split_variants(q)
                    for v in variants:
                        qa_pairs.append((v, a))
                continue
            if stripped.lower().startswith('q:'):
                if pending_qs and answer_lines:
                    answer = "\n".join(answer_lines).strip()
                    for v in pending_qs:
                        qa_pairs.append((v, answer))
                pending_qs = _split_variants(stripped[2:].strip())
                collecting = False
                answer_lines = []
                continue
            if stripped.lower().startswith('a:') and pending_qs:
                collecting = True
                answer_lines.append(stripped[2:].strip())
                continue
            if collecting and pending_qs:
                answer_lines.append(stripped)
        if pending_qs and answer_lines:
            answer = "\n".join(answer_lines).strip()
            for v in pending_qs:
                qa_pairs.append((v, answer))
    except Exception:
        return []
    return qa_pairs

def _normalize_text(text):
    text = text.lower()
    text = re.sub(r"\s+", " ", text).strip()
    text = re.sub(r"[^0-9a-z\u4e00-\u9fff]+", "", text)
    return text
def _bigram_tokens(text):
    if not text:
        return set()
    if len(text) < 2:
        return {text}
    return set(text[i:i+2] for i in range(len(text) - 1))

def match_qa_reply(message_text, qa_pairs):
    if not message_text:
        return None
    msg = message_text.strip()
    if not msg:
        return None
    norm_msg = _normalize_text(msg)
    if not norm_msg:
        return None
    msg_tokens = set(norm_msg[i:i+2] for i in range(len(norm_msg) - 1)) if len(norm_msg) >= 2 else set([norm_msg])
    for q, a in qa_pairs:
        if not q:
            continue
        norm_q = _normalize_text(q)
        if not norm_q:
            continue
        if norm_q in norm_msg or norm_msg in norm_q:
            return a
        # token overlap for short queries
        q_tokens = set(norm_q[i:i+2] for i in range(len(norm_q) - 1)) if len(norm_q) >= 2 else set([norm_q])
        if q_tokens:
            overlap = len(msg_tokens & q_tokens) / max(1, len(q_tokens))
            if overlap >= 0.45:
                return a
        ratio = difflib.SequenceMatcher(None, norm_q, norm_msg).ratio()
        if ratio >= 0.5:
            return a
    return None

def _set_kb_refresh_off():
    try:
        path = os.path.join("platforms", "telegram", "config.txt")
        if not os.path.exists(path): return
        with open(path, "r", encoding="utf-8") as f: lines = f.readlines()
        with open(path, "w", encoding="utf-8") as f:
            for line in lines:
                if line.strip().startswith("KB_REFRESH="):
                    f.write("KB_REFRESH=off\n")
                else:
                    f.write(line)
        log_system("âœ… KB_REFRESH å·²è‡ªåŠ¨é‡ç½®ä¸º off")
    except Exception as e:
        log_system(f"âš ï¸ é‡ç½® KB_REFRESH å¤±è´¥: {e}")

def load_kb_entries():
    """
    åŠ è½½çŸ¥è¯†åº“æ¡ç›®ï¼šä¼˜å…ˆä» SQLite æ•°æ®åº“åŠ è½½
    æ”¯æŒ KB_REFRESH=on å¼ºåˆ¶åˆ·æ–°
    å¦‚æœæ•°æ®åº“ä¸ºç©ºï¼Œåˆ™å°è¯•ä»æœ¬åœ° Knowledge Base.txt è‡ªåŠ¨è§£æå¹¶å¯¼å…¥
    """
    items = []
    
    try:
        # 0. æ£€æŸ¥åˆ·æ–°æŒ‡ä»¤æˆ–å¼‚å¸¸çŠ¶æ€
        config = load_config()
        kb_refresh = str(config.get("KB_REFRESH", "off")).lower() == "on"
        need_reload = kb_refresh

        # å¦‚æœæœªå¼ºåˆ¶åˆ·æ–°ï¼Œå…ˆæ£€æŸ¥æ•°æ®åº“çŠ¶æ€
        if not need_reload:
            db_items = db.get_kb_items("default")
            # å¼‚å¸¸æ£€æµ‹ï¼šåªæœ‰1æ¡è®°å½•ä¸”å†…å®¹æé•¿ï¼ˆ>2000å­—ç¬¦ï¼‰ï¼Œé€šå¸¸æ˜¯é”™è¯¯çš„æ•´æœ¬å¯¼å…¥
            if db_items and len(db_items) == 1 and len(db_items[0].get("content", "")) > 2000:
                log_system("âš ï¸ æ£€æµ‹åˆ°çŸ¥è¯†åº“ç»“æ„å¼‚å¸¸ï¼ˆå•æ¡è¿‡é•¿ï¼‰ï¼Œè§¦å‘è‡ªåŠ¨ä¿®å¤é‡ç½®...")
                need_reload = True
            elif db_items:
                # æ­£å¸¸åŠ è½½
                for it in db_items:
                    if isinstance(it.get("tags"), str):
                        try:
                            it["tags"] = json.loads(it["tags"])
                        except:
                            it["tags"] = [t.strip() for t in it["tags"].split(",") if t.strip()]
                items.extend(db_items)
                log_system(f"ğŸ“š ä»æ•°æ®åº“åŠ è½½äº† {len(items)} æ¡çŸ¥è¯†åº“æ¡ç›®")

        # 1. æ‰§è¡Œé‡ç½®
        if need_reload:
            log_system("ğŸ”„ æ‰§è¡ŒçŸ¥è¯†åº“é‡ç½® (KB_REFRESH/AutoFix)...")
            db.execute_update("DELETE FROM knowledge_base WHERE tenant_id = ?", ("default",))
            items = [] # ç¡®ä¿ä¸ºç©ºï¼Œè§¦å‘ä¸‹æ–¹å¯¼å…¥é€»è¾‘
            if kb_refresh:
                _set_kb_refresh_off()

        # 2. å¦‚æœæ•°æ®åº“ä¸ºç©ºï¼ˆæˆ–å·²é‡ç½®ï¼‰ï¼Œæ‰§è¡Œå¯¼å…¥
        if not items:
            kb_text_file = os.path.join(os.path.dirname(__file__), "platforms", "telegram", "Knowledge Base.txt")
            if os.path.exists(kb_text_file):
                try:
                    with open(kb_text_file, "r", encoding="utf-8-sig") as f:
                        content = f.read()
                    
                    if content.strip():
                        log_system("ğŸ“‚ æ­£åœ¨è§£æå¹¶å¯¼å…¥æœ¬åœ°çŸ¥è¯†åº“...")
                        blocks = _parse_multi_lang_qa(content)
                        md_blocks = []
                        if not blocks:
                            md_blocks = _parse_markdown_kb(content)
                        
                        count = 0
                        ts = datetime.now().isoformat()
                        
                        if blocks:
                            for b in blocks:
                                q_sc = b.get('q_sc', '')
                                q_tc = b.get('q_tc', '')
                                a_sc = b.get('a_sc', '')
                                a_tc = b.get('a_tc', '')
                                
                                # æ„é€ æ›´ä¸°å¯Œçš„æ£€ç´¢å†…å®¹
                                full_content = f"Question: {q_sc}\nQuestion_TC: {q_tc}\nAnswer: {a_sc}\nAnswer_TC: {a_tc}"
                                
                                new_id = str(uuid.uuid4())
                                new_item = {
                                    "id": new_id,
                                    "tenant_id": "default",
                                    "title": q_sc[:100] if q_sc else "æ— æ ‡é¢˜QA",
                                    "category": "qa",
                                    "tags": json.dumps(["telegram", "kb", "parsed"], ensure_ascii=False),
                                    "content": full_content,
                                    "source_file": "platforms/telegram/Knowledge Base.txt",
                                    "created_at": ts,
                                    "updated_at": ts
                                }
                                db.add_kb_item(new_item)
                                
                                # Add to memory
                                new_item["tags"] = ["telegram", "kb", "parsed"]
                                items.append(new_item)
                                count += 1
                            
                            log_system(f"âœ… æˆåŠŸå¯¼å…¥ {count} æ¡ QA çŸ¥è¯†åº“æ¡ç›®ï¼")
                        elif md_blocks:
                            log_system("âš ï¸ QAè§£æä¸ºç©ºï¼Œé‡‡ç”¨ Markdown æ ‡é¢˜åˆ†å‰²å¯¼å…¥...")
                            for mb in md_blocks:
                                new_id = str(uuid.uuid4())
                                new_item = {
                                    "id": new_id,
                                    "tenant_id": "default",
                                    "title": mb['title'][:100],
                                    "category": "markdown",
                                    "tags": json.dumps(["telegram", "kb", "markdown"], ensure_ascii=False),
                                    "content": mb['content'],
                                    "source_file": "platforms/telegram/Knowledge Base.txt",
                                    "created_at": ts,
                                    "updated_at": ts
                                }
                                db.add_kb_item(new_item)
                                new_item["tags"] = ["telegram", "kb", "markdown"]
                                items.append(new_item)
                                count += 1
                            log_system(f"âœ… æˆåŠŸå¯¼å…¥ {count} æ¡ Markdown çŸ¥è¯†åº“æ¡ç›®ï¼")
                        else:
                             # Fallback: å¦‚æœè§£æå¤±è´¥ä½†æ–‡ä»¶ä¸ä¸ºç©ºï¼Œä»å°è¯•æ•´æœ¬å¯¼å…¥ï¼ˆé¿å…å®Œå…¨æ— æ•°æ®ï¼‰
                             log_system("âš ï¸ è§£æç»“æœä¸ºç©ºï¼Œæ‰§è¡Œæ•´æœ¬å¯¼å…¥(Fallback)...")
                             new_id = str(uuid.uuid4())
                             new_item = {
                                "id": new_id,
                                "tenant_id": "default",
                                "title": "é»˜è®¤çŸ¥è¯†åº“ (Fallback)",
                                "category": "text",
                                "tags": json.dumps(["telegram", "kb", "fallback"], ensure_ascii=False),
                                "content": content,
                                "source_file": "platforms/telegram/Knowledge Base.txt",
                                "created_at": ts,
                                "updated_at": ts
                             }
                             db.add_kb_item(new_item)
                             new_item["tags"] = ["telegram", "kb", "fallback"]
                             items.append(new_item)

                except Exception as e:
                    log_system(f"âŒ åˆå§‹åŒ–å¯¼å…¥å¤±è´¥: {e}")

            # 3. å°è¯•å¯¼å…¥ qa.txt (å¦‚æœå­˜åœ¨ä¸”æ•°æ®åº“ä¸ºç©º/é‡ç½®)
            qa_file = os.path.join(os.path.dirname(__file__), "platforms", "telegram", "qa.txt")
            if os.path.exists(qa_file):
                try:
                    with open(qa_file, "r", encoding="utf-8") as f:
                        qa_content = f.read()
                    
                    if qa_content.strip():
                        log_system("ğŸ“‚ æ­£åœ¨è§£æå¹¶å¯¼å…¥ qa.txt (è¡¥å……çŸ¥è¯†åº“)...")
                        qa_blocks = _parse_multi_lang_qa(qa_content)
                        
                        if qa_blocks:
                            qa_count = 0
                            ts = datetime.now().isoformat()
                            for b in qa_blocks:
                                q_sc = b.get('q_sc', '')
                                q_tc = b.get('q_tc', '')
                                a_sc = b.get('a_sc', '')
                                a_tc = b.get('a_tc', '')
                                
                                full_content = f"Question: {q_sc}\nQuestion_TC: {q_tc}\nAnswer: {a_sc}\nAnswer_TC: {a_tc}"
                                
                                new_id = str(uuid.uuid4())
                                new_item = {
                                    "id": new_id,
                                    "tenant_id": "default",
                                    "title": q_sc[:100] if q_sc else "QA Pair",
                                    "category": "qa_txt",
                                    "tags": json.dumps(["telegram", "kb", "qa_txt"], ensure_ascii=False),
                                    "content": full_content,
                                    "source_file": "platforms/telegram/qa.txt",
                                    "created_at": ts,
                                    "updated_at": ts
                                }
                                db.add_kb_item(new_item)
                                items.append(new_item)
                                qa_count += 1
                            log_system(f"âœ… æˆåŠŸä» qa.txt å¯¼å…¥ {qa_count} æ¡çŸ¥è¯†åº“æ¡ç›®ï¼")
                except Exception as e:
                    log_system(f"âš ï¸ å¯¼å…¥ qa.txt å¤±è´¥: {e}")

            # 4. å°è¯•å¯¼å…¥ extra_kb.txt (å¦‚ PDF å¯¼å…¥å†…å®¹)
            extra_file = os.path.join(os.path.dirname(__file__), "platforms", "telegram", "extra_kb.txt")
            if os.path.exists(extra_file):
                try:
                    with open(extra_file, "r", encoding="utf-8") as f:
                        extra_content = f.read()
                    
                    if extra_content.strip():
                        log_system("ğŸ“‚ æ­£åœ¨è§£æå¹¶å¯¼å…¥ extra_kb.txt (é¢å¤–çŸ¥è¯†åº“)...")
                        # ä¼˜å…ˆå°è¯• Markdown è§£æ
                        extra_blocks = _parse_markdown_kb(extra_content)
                        
                        extra_count = 0
                        ts = datetime.now().isoformat()
                        
                        if extra_blocks:
                            for mb in extra_blocks:
                                new_id = str(uuid.uuid4())
                                new_item = {
                                    "id": new_id,
                                    "tenant_id": "default",
                                    "title": mb['title'][:100],
                                    "category": "markdown",
                                    "tags": json.dumps(["telegram", "kb", "extra"], ensure_ascii=False),
                                    "content": mb['content'],
                                    "source_file": "platforms/telegram/extra_kb.txt",
                                    "created_at": ts,
                                    "updated_at": ts
                                }
                                db.add_kb_item(new_item)
                                items.append(new_item)
                                extra_count += 1
                            log_system(f"âœ… æˆåŠŸä» extra_kb.txt å¯¼å…¥ {extra_count} æ¡ Markdown çŸ¥è¯†åº“æ¡ç›®ï¼")
                        else:
                             # Fallback to full content
                             log_system("âš ï¸ extra_kb.txt è§£æç»“æœä¸ºç©ºï¼Œæ‰§è¡Œæ•´æœ¬å¯¼å…¥...")
                             new_id = str(uuid.uuid4())
                             new_item = {
                                "id": new_id,
                                "tenant_id": "default",
                                "title": "é¢å¤–çŸ¥è¯†åº“ (Full)",
                                "category": "text",
                                "tags": json.dumps(["telegram", "kb", "extra", "fallback"], ensure_ascii=False),
                                "content": extra_content,
                                "source_file": "platforms/telegram/extra_kb.txt",
                                "created_at": ts,
                                "updated_at": ts
                             }
                             db.add_kb_item(new_item)
                             items.append(new_item)
                             log_system("âœ… æˆåŠŸä» extra_kb.txt å¯¼å…¥æ•´æœ¬å†…å®¹")

                except Exception as e:
                    log_system(f"âš ï¸ å¯¼å…¥ extra_kb.txt å¤±è´¥: {e}")

    except Exception as e:
        log_system(f"âš ï¸ åŠ è½½çŸ¥è¯†åº“å¤±è´¥: {e}")
        
    return items

def retrieve_kb_context(query_text, kb_items, topn=2):
    if not query_text or (not kb_items):
        return []
    norm_q = _normalize_text(query_text)
    if not norm_q:
        return []
    q_tokens = _bigram_tokens(norm_q)
    scored = []
    for it in kb_items:
        title = _normalize_text((it.get("title","") or ""))
        content = _normalize_text((it.get("content","") or ""))
        if not title and not content:
            continue
        t_tokens = _bigram_tokens(title)
        c_tokens = _bigram_tokens(content)
        title_overlap = len(q_tokens & t_tokens) / max(1, len(q_tokens))
        content_overlap = len(q_tokens & c_tokens) / max(1, len(q_tokens))
        bonus = 0.0
        if norm_q in title or title in norm_q:
            bonus += 0.6
        if norm_q in content or content in norm_q:
            bonus += 0.3
        base = 2.0 * title_overlap + 1.0 * content_overlap + bonus
        if base == 0.0:
            text_all = title + content
            base = difflib.SequenceMatcher(None, norm_q, text_all).ratio() * 0.5
        scored.append((base, it))
    scored.sort(key=lambda x: x[0], reverse=True)
    return [it for _, it in scored[:max(1, topn)]]

def _split_sentences(s):
    if not s:
        return []
    parts = re.split(r"[ã€‚ï¼ï¼Ÿ!?\n]+", s)
    return [p.strip() for p in parts if p.strip()]

def _is_single_point_question(text):
    if not text:
        return False
    t = text.strip()
    if len(t) <= 2:
        return False
    if re.search(r"(æ˜¯ä»€ä¹ˆ|æ€ä¹ˆç®—|å¦‚ä½•|æ˜¯å¦|è´¹ç”¨|ä»·æ ¼|æ”¶è´¹|æµç¨‹|è§„åˆ™|è®¡ç®—|æ€ä¹ˆç®—|æ€ä¹ˆè®¡ç®—)", t):
        if not re.search(r"(ã€|ä»¥åŠ|å’Œ|å¹¶ä¸”)", t):
            return True
    return False

def _is_clear_question(text):
    if not text:
        return False
    t = text.strip()
    if len(t) < 6:
        return False
    if re.search(r"[?ï¼Ÿ]", t):
        return True
    if re.search(r"(æ€ä¹ˆ|å¦‚ä½•|æ˜¯å¦|å¤šå°‘|ä¸ºä»€ä¹ˆ|ä¸ºä»€éº¼|è¦å‰‡|è§„åˆ™|è¨ˆç®—|è®¡ç®—|æµç¨‹|ä»·æ ¼|è²»ç”¨|è´¹ç”¨|æ”¶è´¹)", t):
        return True
    return False

def _kb_is_qa_like(item):
    cat = (item.get("category","") or "").lower()
    title = (item.get("title","") or "").lower()
    tags = item.get("tags", [])
    if isinstance(tags, str):
        try:
            tags = json.loads(tags)
        except Exception:
            tags = [tags]
    tlist = [str(x).lower() for x in tags] if isinstance(tags, list) else []
    qa_keys = ["å®¢æœè¯æœ¯","q&a","qa","faq","é—®ç­”","è¯æœ¯"]
    for k in qa_keys:
        if k in cat or k in title or any(k in str(tx) for tx in tlist):
            return True
    return False

def detect_qa_only(query_text, kb_hits):
    reason = {}
    if not _is_clear_question(query_text or ""):
        return False, {}
    if kb_hits:
        if any(_kb_is_qa_like(it) for it in kb_hits):
            reason["kb_doc_type"] = True
    if _is_single_point_question(query_text or ""):
        reason["single_clear_question"] = True
    if not reason:
        return False, {}
    return True, reason

def _filter_sentences_by_user(text, user_text):
    sents = _split_sentences(text)
    if not sents:
        return text
    u = _normalize_text(user_text or "")
    utoks = _bigram_tokens(u)
    kept = []
    for s in sents:
        ns = _normalize_text(s)
        stoks = _bigram_tokens(ns)
        overlap = len(utoks & stoks) / max(1, len(stoks))
        if overlap >= 0.15 or (re.search(r"\d", s) or "%" in s):
            kept.append(s)
    if not kept:
        kept = sents
    return "ã€‚".join(kept) + ("ã€‚" if kept else "")

def build_qa_only_guidance():
    return (
        "å¿…é¡»ä½¿ç”¨ QA_ONLY æ¨¡å¼ï¼šä»…å›ç­”å½“å‰é—®é¢˜ï¼›æœ€å¤šä¸€ä¸ªç­”æ¡ˆå—ï¼›"
        "ç­”æ¡ˆç»“æ„ä¸º1å¥ç»“è®ºï¼Œå¯é€‰1-3å¥è¡¥å……ï¼›ç¦æ­¢æ‰©å±•åˆ°æœªè¢«é—®åŠçš„é—®é¢˜ï¼›"
        "ç¦æ­¢è¾“å‡ºæ–‡æ¡£æ ‡é¢˜ã€ç›®å½•ã€é¡µç ã€ç‰ˆæƒã€Q:/A: åŸå§‹æ ¼å¼ï¼›"
        "å¦‚å‡ºç°å¤šä¸ªä¸åŒé—®é¢˜ç‚¹æˆ–æœªåœ¨é—®é¢˜ä¸­çš„æ ¸å¿ƒå…³é”®è¯ï¼Œè‡ªåŠ¨å‹ç¼©ï¼Œä»…ä¿ç•™æœ€ç›¸å…³å†…å®¹ï¼›"
        "æ•°å€¼/è§„åˆ™ç±»é—®é¢˜ä¼˜å…ˆç»™å‡ºæ˜ç¡®ç»“è®ºä¸å¿…è¦è¯´æ˜ï¼Œé¿å…èƒŒæ™¯é“ºå«ã€‚"
    )

def build_conversation_mode_guidance(mode):
    if mode == 'human_simulated':
        return (
            "ã€é‡è¦æŒ‡ä»¤ã€‘ä½ ç°åœ¨å¿…é¡»å®Œå…¨æ¨¡æ‹ŸçœŸäººè¿›è¡Œå›å¤ã€‚"
            "1. ç¦æ­¢è‡ªç§°â€œç³»ç»Ÿâ€ã€â€œAIâ€ã€â€œæœºå™¨äººâ€æˆ–â€œå®˜æ–¹å®¢æœâ€ã€‚"
            "2. ç¦æ­¢ä½¿ç”¨â€œè®°å½•â€ã€â€œæŠ€æœ¯ä¸“å®¶â€ã€â€œåé¦ˆâ€ç­‰ç³»ç»Ÿæ€§æœ¯è¯­ã€‚"
            "3. ä¸è¦ä¸»åŠ¨æå‡ºâ€œä¸ºæ‚¨è½¬æ¥äººå·¥â€æˆ–è§£é‡Šä½ åœ¨åšä»€ä¹ˆã€‚"
            "4. å¦‚æœä¸ç†è§£ç”¨æˆ·æ„æ€ï¼Œç›´æ¥åé—®â€œä»€ä¹ˆæ„æ€ï¼Ÿâ€ã€â€œæ²¡çœ‹æ‡‚â€ç­‰å£è¯­åŒ–è¡¨è¾¾ã€‚"
            "5. è¯­æ°”è¦è‡ªç„¶ã€ç®€çŸ­ï¼Œåƒæœ‹å‹èŠå¤©ä¸€æ ·ã€‚"
        )
    return ""

def enforce_qa_only(text, user_text):
    if not text:
        return text
    s = (text or "").strip()
    prefer_tc = False
    if re.search(r"[ç¹é«”è‡ºç£å¹£è£¡è£æ–¼å°‡é€™éº¼ç‚ºéº¼å¾Œè‡º]", (user_text or "")):
        prefer_tc = True
    patterns_sc = [r"ã€ç­”æ¡ˆ-ç®€ä½“ã€‘(.*?)(?=\n|====|QA-|$)"]
    patterns_tc = [r"ã€ç­”æ¡ˆ-ç¹ä½“ã€‘(.*?)(?=\n|====|QA-|$)"]
    patterns = (patterns_tc + patterns_sc) if prefer_tc else (patterns_sc + patterns_tc)
    picked = None
    for pat in patterns:
        m = re.search(pat, s, re.DOTALL)
        if m:
            picked = m.group(1).strip()
            break
    if picked is None:
        s = re.sub(r"(^|\n)\s*(Q[:ï¼š]|A[:ï¼š]).*", "", s)
        s = re.sub(r"(ç›®å½•|é¡µç |ç‰ˆæƒä¿¡æ¯|API|ç´¢å¼•|ã€é—®é¢˜[^ã€‘]*ã€‘|ã€ç­”æ¡ˆ[^ã€‘]*ã€‘|QA-[0-9]+|====)", "", s).strip()
        if not s:
            return ""
        picked = s
    picked = picked.split("\n")[0].strip()
    if _has_illegal_markers(picked):
        return ""
    if re.search(r"[\u4e00-\u9fff]", picked) and not re.search(r"[ã€‚ï¼ï¼Ÿ!?]$", picked):
        picked = picked + "ã€‚"
    return picked

def _has_illegal_markers(s):
    if not s:
        return False
    markers = ["QA-", "ã€é—®é¢˜", "ã€ç­”æ¡ˆ", "===="]
    return any(m in s for m in markers)

def enforce_qa_only_single_line(text, user_text):
    if not text:
        return text
    s = text.strip()
    s = s.splitlines()[0] if "\n" in s else s
    s = s.split("====")[0]
    s = re.sub(r"(^|\n)\s*(Q[:ï¼š]|A[:ï¼š]).*", "", s)
    s = re.sub(r"(ç›®å½•|é¡µç |ç‰ˆæƒä¿¡æ¯|API|ç´¢å¼•|ã€é—®é¢˜[^ã€‘]*ã€‘|ã€ç­”æ¡ˆ[^ã€‘]*ã€‘|QA-[0-9]+)", "", s)
    s = s.strip()
    if not s:
        return ""
    if _has_illegal_markers(s):
        s = re.sub(r"(ã€é—®é¢˜[^ã€‘]*ã€‘|ã€ç­”æ¡ˆ[^ã€‘]*ã€‘|QA-[0-9]+|====)", "", s).strip()
    if re.search(r"[\u4e00-\u9fff]", s) and not re.search(r"[ã€‚ï¼ï¼Ÿ!?]$", s):
        s = s + "ã€‚"
    return s

def _parse_qa_pairs_from_text(content):
    pairs = []
    if not content:
        return pairs
    lines = content.splitlines()
    pending_q = None
    answer_lines = []
    collecting = False
    for raw in lines:
        line = (raw or "").strip()
        if not line:
            if collecting and pending_q:
                answer_lines.append("")
            continue
        if line.lower().startswith("q:"):
            if pending_q and answer_lines:
                pairs.append((pending_q.strip(), "\n".join(answer_lines).strip()))
            pending_q = line[2:].strip()
            answer_lines = []
            collecting = False
            continue
        if line.lower().startswith("a:"):
            collecting = True
            answer_lines.append(line[2:].strip())
            continue
        if collecting and pending_q:
            answer_lines.append(line)
    if pending_q and answer_lines:
        pairs.append((pending_q.strip(), "\n".join(answer_lines).strip()))
    return pairs

def _parse_multi_lang_qa(content):
    blocks = []
    if not content:
        return blocks
    lines = content.splitlines()
    cur = {"q_sc":"", "q_tc":"", "a_sc":"", "a_tc":""}
    cur_key = None
    def flush():
        nonlocal cur
        if any(cur.values()):
            blocks.append({k: (v.strip()) for k, v in cur.items()})
        cur = {"q_sc":"", "q_tc":"", "a_sc":"", "a_tc":""}
    for raw in lines:
        line = (raw or "").strip()
        if not line:
            if cur_key:
                (cur[cur_key] if cur_key else "")
            continue
        if line.startswith("====="):
             continue
        if line.startswith("QA-"):
            flush()
            cur_key = None
            continue
        if line.startswith("ã€é—®é¢˜-ç®€ä½“ã€‘"):
            cur_key = "q_sc"
            cur[cur_key] += line.replace("ã€é—®é¢˜-ç®€ä½“ã€‘", "").strip()
            continue
        if line.startswith("ã€é—®é¢˜-ç¹ä½“ã€‘"):
            cur_key = "q_tc"
            cur[cur_key] += line.replace("ã€é—®é¢˜-ç¹ä½“ã€‘", "").strip()
            continue
        if line.startswith("ã€ç­”æ¡ˆ-ç®€ä½“ã€‘"):
            cur_key = "a_sc"
            cur[cur_key] += line.replace("ã€ç­”æ¡ˆ-ç®€ä½“ã€‘", "").strip()
            continue
        if line.startswith("ã€ç­”æ¡ˆ-ç¹ä½“ã€‘"):
            cur_key = "a_tc"
            cur[cur_key] += line.replace("ã€ç­”æ¡ˆ-ç¹ä½“ã€‘", "").strip()
            continue
        if cur_key:
            cur[cur_key] += ("\n" + line)
    flush()
    return [b for b in blocks if any(b.values())]

def _match_multi_lang_qa(blocks, user_msg):
    if not blocks or not user_msg:
        return None
    norm_msg = _normalize_text(user_msg)
    best = None
    best_score = -1.0
    for b in blocks:
        qsc = _normalize_text(b.get("q_sc",""))
        qtc = _normalize_text(b.get("q_tc",""))
        score_sc = difflib.SequenceMatcher(None, norm_msg, qsc).ratio() if qsc else -1.0
        score_tc = difflib.SequenceMatcher(None, norm_msg, qtc).ratio() if qtc else -1.0
        if score_sc > best_score:
            best_score = score_sc
            best = ("sc", b.get("a_sc",""))
        if score_tc > best_score:
            best_score = score_tc
            best = ("tc", b.get("a_tc",""))
    if best is None:
        return None
    return best

def _parse_markdown_kb(content):
    """
    é€šç”¨ Markdown åˆ†å‰²å™¨ï¼šæŒ‰æ ‡é¢˜ï¼ˆ#ï¼‰åˆ†å‰²çŸ¥è¯†åº“
    """
    lines = content.splitlines()
    blocks = []
    current_title = "General"
    current_content = []
    
    for line in lines:
        if line.strip().startswith('#'):
            if current_content:
                text = "\n".join(current_content).strip()
                if text:
                    blocks.append({"title": current_title, "content": text})
            current_title = line.strip().lstrip('#').strip()
            current_content = [line]
        else:
            current_content.append(line)
            
    if current_content:
        text = "\n".join(current_content).strip()
        if text:
            blocks.append({"title": current_title, "content": text})
            
    return blocks

def load_config():
    """
    çƒ­æ›´æ–°åŠŸèƒ½ï¼šä» config.txt è¯»å–åŠŸèƒ½å¼€å…³é…ç½®
    è¿”å›é…ç½®å­—å…¸
    """
    config_file = "platforms/telegram/config.txt"
    config = {
        'PRIVATE_REPLY': True,   # é»˜è®¤å¼€å¯ç§èŠå›å¤
        'GROUP_REPLY': True,     # é»˜è®¤å¼€å¯ç¾¤èŠå›å¤
        'GROUP_CONTEXT': False,  # æ˜¯å¦åœ¨ç¾¤èŠä¸­å¼€å¯ä¸Šä¸‹æ–‡è‡ªåŠ¨å›å¤ï¼ˆæ— å…³é”®è¯ï¼‹æœªè¢« @ æ—¶ä¹Ÿå¯å›å¤ï¼‰
        'AI_TEMPERATURE': 0.7,   # AI æ¸©åº¦ï¼Œé»˜è®¤ 0.7
        'AUDIT_ENABLED': True,   # é»˜è®¤å¼€å¯å†…å®¹å®¡æ ¸
        'AUDIT_MAX_RETRIES': 3,  # é»˜è®¤æœ€å¤§é‡è¯•æ¬¡æ•°
        'AUDIT_TEMPERATURE': 0.0, # é»˜è®¤å®¡æ ¸æ¸©åº¦
        'REPLY_DELAY_MIN_SECONDS': 3.0,
        'REPLY_DELAY_MAX_SECONDS': 10.0,
        'AUTO_QUOTE': False,
        'QUOTE_INTERVAL_SECONDS': 30.0,
        'QUOTE_MAX_LEN': 200,
        'CONV_ORCHESTRATION': False,
        'KB_ONLY_REPLY': False,
        'CONVERSATION_MODE': 'ai_visible'  # ai_visible / human_simulated
    }
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
                if not line or line.startswith('#'):
                    continue
                
                # è§£æé…ç½®è¡Œï¼šKEY=VALUE
                if '=' in line:
                    key, value = line.split('=', 1)
                    key = key.strip()
                    value = value.strip().lower()
                    raw_value = line.split('=', 1)[1].strip()
                    
                    if key in ['PRIVATE_REPLY', 'GROUP_REPLY', 'GROUP_CONTEXT', 'AUDIT_ENABLED', 'AUTO_QUOTE', 'CONV_ORCHESTRATION', 'KB_ONLY_REPLY']:
                        config[key] = (value == 'on')
                    elif key == 'CONVERSATION_MODE':
                        if value in ['ai_visible', 'human_simulated']:
                            config[key] = value
                    elif key in ['AI_TEMPERATURE', 'AUDIT_TEMPERATURE']:
                        try:
                            config[key] = float(value)
                        except ValueError:
                            pass
                    elif key in ['REPLY_DELAY_MIN_SECONDS', 'REPLY_DELAY_MAX_SECONDS', 'QUOTE_INTERVAL_SECONDS']:
                        try:
                            config[key] = float(value)
                        except ValueError:
                            pass
                    elif key == 'AUDIT_MAX_RETRIES':
                        try:
                            config[key] = int(value)
                        except ValueError:
                            pass
                    elif key == 'AUDIT_MODE':
                        config[key] = value
                    elif key == 'AUDIT_SERVERS':
                        config[key] = raw_value
                    elif key == 'HANDOFF_KEYWORDS':
                        config[key] = raw_value
                    elif key == 'HANDOFF_MESSAGE':
                        config[key] = raw_value
                    elif key == 'KB_FALLBACK_MESSAGE':
                        config[key] = raw_value
                    elif key == 'QUOTE_MAX_LEN':
                        try:
                            config[key] = int(value)
                        except ValueError:
                            pass
        
        return config
    except FileNotFoundError:
        log_system(f"âš ï¸ æœªæ‰¾åˆ° {config_file}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        return config
    except Exception as e:
        log_system(f"âš ï¸ è¯»å– {config_file} å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        return config

TG_PLATFORM_DIR = "platforms/telegram"
GROUP_CACHE_FILE = os.path.join(TG_PLATFORM_DIR, "group_cache.json")
SELECTED_GROUPS_FILE = os.path.join(TG_PLATFORM_DIR, "selected_groups.json")

def load_group_cache():
    try:
        with open(GROUP_CACHE_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
            if isinstance(data, dict):
                return data
    except:
        pass
    return {}

def save_group_cache(cache):
    os.makedirs(os.path.dirname(GROUP_CACHE_FILE), exist_ok=True)
    with open(GROUP_CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(cache, f, ensure_ascii=False, indent=2)

async def record_group(event):
    if not event.is_group:
        return
    chat_id = getattr(event, 'chat_id', None)
    if chat_id is None:
        return
    chat_id_str = str(chat_id)
    cache = load_group_cache()
    chat_obj = getattr(event, 'chat', None) or getattr(event.message, 'chat', None)
    title = ""
    if chat_obj:
        title = getattr(chat_obj, 'title', None) or getattr(chat_obj, 'name', None) or ""
    else:
        try:
            chat = await event.get_chat()
            title = getattr(chat, 'title', None) or getattr(chat, 'name', None) or ""
        except:
            title = ""
    entry = dict(cache.get(chat_id_str, {}))
    entry['title'] = title or entry.get('title', '')
    entry['last_seen'] = datetime.now().isoformat()
    cache[chat_id_str] = entry
    save_group_cache(cache)
    descriptor = title or str(chat_id)
    log_system(f"ğŸ—‚ï¸ ç¼“å­˜ç¾¤èŠ: {descriptor} ({chat_id})")

def load_selected_group_ids():
    try:
        with open(SELECTED_GROUPS_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        raw_ids = data.get('selected_ids', [])
        result = set()
        for raw in raw_ids:
            try:
                result.add(int(raw))
            except:
                pass
        return result
    except:
        return set()


def load_stats():
    """åŠ è½½ç»Ÿè®¡æ•°æ®"""
    stats_file = "platforms/telegram/stats.json"
    default_stats = {
        "total_messages": 0,
        "total_replies": 0,
        "private_messages": 0,
        "group_messages": 0,
        "success_count": 0,
        "error_count": 0,
        "start_time": datetime.now().isoformat(),
        "last_active": None
    }
    
    try:
        with open(stats_file, 'r', encoding='utf-8') as f:
            stats = json.load(f)
            if stats.get('start_time') is None:
                stats['start_time'] = datetime.now().isoformat()
            return stats
    except:
        return default_stats

def save_stats(stats):
    """ä¿å­˜ç»Ÿè®¡æ•°æ®"""
    stats_file = "platforms/telegram/stats.json"
    try:
        stats['last_active'] = datetime.now().isoformat()
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
    except Exception as e:
        log_system(f"âš ï¸ ä¿å­˜ç»Ÿè®¡å¤±è´¥: {e}")

async def get_chat_history(chat_id, limit=8, max_id=0):
    """è·å–èŠå¤©ä¸Šä¸‹æ–‡"""
    messages = []
    try:
        async for msg in client.iter_messages(chat_id, limit=limit, max_id=max_id):
            if msg.text:
                role = "assistant" if msg.out else "user"
                messages.append({"role": role, "content": msg.text})
        return messages[::-1]
    except Exception:
        return []

async def _get_prev_incoming_message(chat_id, max_id=0):
    try:
        async for msg in client.iter_messages(chat_id, limit=1, max_id=max_id):
            if msg and msg.text and not msg.out:
                return msg
    except Exception:
        return None
    return None

def _similar(a, b):
    if not a or not b:
        return 0.0
    na = _normalize_text(a)
    nb = _normalize_text(b)
    if not na or not nb:
        return 0.0
    ta = _bigram_tokens(na)
    tb = _bigram_tokens(nb)
    if ta and tb:
        return len(ta & tb) / max(1, len(ta))
    return difflib.SequenceMatcher(None, na, nb).ratio()

async def _should_auto_quote(event, msg, config):
    if not config.get('AUTO_QUOTE', False):
        return False
    prev = await _get_prev_incoming_message(event.chat_id, max_id=event.id)
    if not prev:
        return False
    try:
        now = event.message.date
        diff = (now - prev.date).total_seconds()
    except Exception:
        diff = 9999.0
    if diff > float(config.get('QUOTE_INTERVAL_SECONDS', 30.0)):
        return False
    sim = _similar(msg or "", prev.text or "")
    if sim < 0.25:
        return False
    return True

@client.on(events.NewMessage(incoming=True))
async def handler(event):
    # åªå¤„ç†æœ‰æ–‡æœ¬å†…å®¹çš„æ¶ˆæ¯
    if not event.message.text:
        return
    
    # 1. MSG_RECEIVED (Trace Start)
    trace_id = str(uuid.uuid4())
    msg = event.message.text
    sender = await event.get_sender()
    user_id = str(event.chat_id)
    
    # åŠ è½½ç»Ÿè®¡æ•°æ®
    stats = load_stats()
    stats['total_messages'] += 1
    
    name = getattr(sender, 'first_name', 'æœ‹å‹')
    
    # ã€çƒ­æ›´æ–°ã€‘å®æ—¶è¯»å–é…ç½®
    config = load_config()
    keywords = load_keywords()
    context_reply_enabled = config.get('GROUP_CONTEXT', False)
    orch_enabled = bool(config.get('CONV_ORCHESTRATION', False))
    
    # è®°å½•æ¶ˆæ¯ç±»å‹
    if event.is_private:
        stats['private_messages'] += 1
    elif event.is_group:
        stats['group_messages'] += 1

    if orch_enabled:
        log_trace_event(trace_id, "MSG_RECEIVED", {
            "user_id": user_id,
            "content_len": len(msg),
            "platform": "telegram"
        })
    
    # ã€åŠŸèƒ½å¼€å…³æ£€æŸ¥ã€‘
    if event.is_private and not config['PRIVATE_REPLY']:
        # ç§èŠå›å¤å·²å…³é—­
        log_private(f"[trace:{trace_id}] ğŸ”• ç§èŠå›å¤å·²å…³é—­ï¼Œå¿½ç•¥æ¶ˆæ¯ [{name}]: {msg}")
        return
    
    if event.is_group and not config['GROUP_REPLY']:
        # ç¾¤èŠå›å¤å·²å…³é—­
        log_group(f"ğŸ”• ç¾¤èŠå›å¤å·²å…³é—­ï¼Œå¿½ç•¥æ¶ˆæ¯ [{name}]: {msg}")
        return

    if event.is_group:
        await record_group(event)
        selected_group_ids = load_selected_group_ids()
        if selected_group_ids:
            chat_id = getattr(event, 'chat_id', None)
            if chat_id is None or int(chat_id) not in selected_group_ids:
                chat_obj = getattr(event, 'chat', None) or getattr(event.message, 'chat', None)
                chat_name = getattr(chat_obj, 'title', None) or getattr(chat_obj, 'name', None) if chat_obj else ""
                descriptor = chat_name or str(chat_id)
                log_group(f"ğŸ›‘ ç¾¤èŠ [{descriptor}] ä¸åœ¨ç™½åå•ï¼Œè·³è¿‡å›å¤")
                return
    
    # ã€æ™ºèƒ½è§¦å‘é€»è¾‘ã€‘
    should_reply = False
    
    if event.is_private:
        # ç§èŠï¼šç›´æ¥å›å¤ï¼ˆå·²ç»é€šè¿‡å¼€å…³æ£€æŸ¥ï¼‰
        should_reply = True
        log_private(f"[trace:{trace_id}] ğŸ“© æ”¶åˆ°ç§èŠ [{name}]: {msg}")
    elif event.is_group:
        # ç¾¤èŠï¼šéœ€è¦æ»¡è¶³ä»¥ä¸‹ä»»ä¸€æ¡ä»¶ï¼ˆå·²ç»é€šè¿‡å¼€å…³æ£€æŸ¥ï¼‰
        if event.mentioned:
            # æ¡ä»¶1ï¼šè¢« @ äº†
            should_reply = True
            log_group(f"ğŸ“© ç¾¤èŠè¢« @ [{name}]: {msg}")
        elif keywords:
            # æ¡ä»¶2ï¼šæ¶ˆæ¯åŒ…å«å…³é”®è¯
            for keyword in keywords:
                if keyword.lower() in msg.lower():
                    should_reply = True
                    log_group(f"ğŸ“© ç¾¤èŠè§¦å‘å…³é”®è¯ [{keyword}] [{name}]: {msg}")
                    break
        elif context_reply_enabled:
            should_reply = True
            log_group(f"ğŸ“© ç¾¤èŠä¸Šä¸‹æ–‡è§¦å‘ [{name}]: {msg}")
    
    # å¦‚æœä¸æ»¡è¶³å›å¤æ¡ä»¶ï¼Œç›´æ¥è¿”å›
    if not should_reply:
        return

    def _handoff_intent_detect(user_msg):
        if not user_msg:
            return False
        s = (user_msg or "").strip().lower()
        keys_raw = str(config.get('HANDOFF_KEYWORDS', '') or '')
        keys = [k.strip().lower() for k in keys_raw.split(',') if k.strip()]
        if keys and any(k in s for k in keys):
            return True
        return False

    if _handoff_intent_detect(msg):
        reply = (config.get('HANDOFF_MESSAGE') or "").strip()
        if not reply:
            log_system("âš ï¸ HANDOFF_MESSAGE æœªé…ç½®ï¼Œå·²ç¦æ­¢é»˜è®¤å…œåº•ï¼›è·³è¿‡å‘é€")
            return
        dmin = float(config.get('REPLY_DELAY_MIN_SECONDS', 3.0))
        dmax = float(config.get('REPLY_DELAY_MAX_SECONDS', 10.0))
        if dmin > dmax:
            dmin, dmax = dmax, dmin
        delay = random.uniform(dmin, dmax)
        await asyncio.sleep(delay)
        use_quote = await _should_auto_quote(event, msg, config)
        if use_quote:
            await event.reply(reply)
        else:
            await client.send_message(event.chat_id, reply)
        if event.is_private:
            log_private(f"[trace:{trace_id}] HANDOFF_REPLY: {reply}")
        else:
            log_group(f"HANDOFF_REPLY: {reply}")
        stats['total_replies'] += 1
        stats['success_count'] += 1
        save_stats(stats)
        return

    async with client.action(event.chat_id, 'typing'):
        # ã€çƒ­æ›´æ–°ã€‘æ¯æ¬¡å¤„ç†æ¶ˆæ¯å‰é‡æ–°è¯»å–æç¤ºè¯
        system_prompt = load_system_prompt()
        
        # è·å–å†å²è®°å½•ï¼ˆä¿æŒä¸Šä¸‹æ–‡ï¼‰
        history = await get_chat_history(event.chat_id, max_id=event.id)
        qa_file = os.path.join(os.path.dirname(__file__), 'platforms', 'telegram', 'qa.txt')
        qa_pairs = load_qa_pairs(qa_file)
        qa_reply = match_qa_reply(msg, qa_pairs)
        if qa_reply:
            log_trace_event(trace_id, "QA_HIT", {"reply_len": len(qa_reply)})
            await event.reply(qa_reply)
            log_trace_event(trace_id, "REPLY_SENT", {"content_len": len(qa_reply)})
            if event.is_private:
                log_private(f"[trace:{trace_id}] QA_REPLY: {qa_reply}")
            else:
                log_group(f"QA_REPLY: {qa_reply}")
            return
        
        # é»˜è®¤ä¸Šä¸‹æ–‡å¤„ç†
        kb_items = load_kb_entries()
        kb_context = ""
        system_with_kb = system_prompt

        if config.get('KB_ONLY_REPLY', False):
            if _handoff_intent_detect(msg):
                conv_mode = config.get('CONVERSATION_MODE', 'ai_visible')
                reply = get_mode_specific_response(conv_mode, 'handoff')
                
                if not reply:
                    log_system("âš ï¸ HANDOFF_MESSAGE æœªé…ç½®ï¼ˆKB_ONLY åˆ†æ”¯ï¼‰ï¼Œè·³è¿‡å‘é€")
                    return
                dmin = float(config.get('REPLY_DELAY_MIN_SECONDS', 3.0))
                dmax = float(config.get('REPLY_DELAY_MAX_SECONDS', 10.0))
                if dmin > dmax:
                    dmin, dmax = dmax, dmin
                delay = random.uniform(dmin, dmax)
                await asyncio.sleep(delay)
                use_quote = await _should_auto_quote(event, msg, config)
                if use_quote:
                    await event.reply(reply)
                else:
                    await client.send_message(event.chat_id, reply)
                if event.is_private:
                    log_private(f"[trace:{trace_id}] KB_ONLY_HANDOFF: {reply}")
                else:
                    log_group(f"KB_ONLY_HANDOFF: {reply}")
                stats['total_replies'] += 1
                stats['success_count'] += 1
                save_stats(stats)
                return
            log_system(f"[Trace] KB_ONLY Logic. Msg: {msg[:30]}...")
            kb_hits = retrieve_kb_context(msg, kb_items, topn=3)
            log_system(f"[Trace] KB Search Hits: {len(kb_hits)}")
            for i, hit in enumerate(kb_hits):
                log_system(f"  Hit {i}: {hit.get('title','')} (len={len(hit.get('content',''))})")

            reply = ""
            if kb_hits:
                # Concatenate contents
                context_text = "\n\n".join([f"--- Doc {i+1} ---\n{it.get('content','')}" for i, it in enumerate(kb_hits)])
                
                conv_mode = config.get('CONVERSATION_MODE', 'ai_visible')
                mode_guidance = build_conversation_mode_guidance(conv_mode)
                
                sys_prompt = (
                    "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹çŸ¥è¯†åº“å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n"
                    "å¦‚æœçŸ¥è¯†åº“ä¸­åŒ…å«ç­”æ¡ˆï¼Œè¯·ç›´æ¥å›ç­”ï¼Œä¸è¦æåŠâ€œæ ¹æ®çŸ¥è¯†åº“â€æˆ–â€œæ–‡æ¡£â€ã€‚\n"
                    "å¦‚æœçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·ç›´æ¥å›å¤: NO_ANSWER_FOUND\n"
                    "è¯·ä½¿ç”¨ä¸ç”¨æˆ·æé—®ç›¸åŒçš„è¯­è¨€ï¼ˆç®€ä½“æˆ–ç¹ä½“ï¼‰å›ç­”ã€‚\n"
                    f"{mode_guidance}\n"
                    f"\nã€çŸ¥è¯†åº“å†…å®¹ã€‘\n{context_text}"
                )
                
                log_system(f"[Trace] Calling LLM (Model: {AI_MODEL_NAME})...")
                
                # ğŸ” è‡ªåŠ¨é‡è¯•é€»è¾‘ (å¤„ç† SSL è¿æ¥é”™è¯¯)
                for attempt in range(2):
                    try:
                        ai = get_ai_client()
                        resp = await ai.chat.completions.create(
                            model=AI_MODEL_NAME,
                            messages=[
                                {"role": "system", "content": sys_prompt},
                                {"role": "user", "content": msg}
                            ],
                            temperature=0.3
                        )
                        ans = resp.choices[0].message.content.strip()
                        log_system(f"[Trace] LLM Response: {ans[:50]}...")

                        if "NO_ANSWER_FOUND" not in ans:
                            reply = ans
                        else:
                            log_system("[Trace] LLM returned NO_ANSWER_FOUND")
                        
                        break # æˆåŠŸåˆ™è·³å‡ºå¾ªç¯

                    except APIConnectionError as e:
                        # å¦‚æœæ˜¯è¿æ¥é”™è¯¯ï¼Œä¸”å½“å‰å¯ç”¨äº† SSL éªŒè¯ï¼Œå°è¯•å…³é—­éªŒè¯é‡è¯•
                        if attempt == 0 and _ssl_verify_default():
                            log_system(f"âš ï¸ è¿æ¥å¤±è´¥: {e}ã€‚æ­£åœ¨å°è¯•å…³é—­ SSL éªŒè¯å¹¶é‡è¯•...")
                            os.environ["HTTPX_VERIFY_SSL"] = "false"
                            reset_ai_client()
                            continue
                        else:
                            log_system(f"âš ï¸ KB_ONLY LLM Error (Connection): {e}")
                            break
                    except Exception as e:
                        log_system(f"âš ï¸ KB_ONLY LLM Error: {e} (Type: {type(e)})")
                        break

            else:
                 log_system("[Trace] No KB hits found.")

            if not reply:
                log_system("[Trace] Using Fallback Message.")

            if not reply:
                reply = (config.get('KB_FALLBACK_MESSAGE') or "").strip()
                if not reply:
                    log_system("âš ï¸ KB_FALLBACK_MESSAGE æœªé…ç½®ï¼ˆKB_ONLY RAG Missï¼‰ï¼Œè·³è¿‡å‘é€")
                    return
            dmin = float(config.get('REPLY_DELAY_MIN_SECONDS', 3.0))
            dmax = float(config.get('REPLY_DELAY_MAX_SECONDS', 10.0))
            if dmin > dmax:
                dmin, dmax = dmax, dmin
            delay = random.uniform(dmin, dmax)
            await asyncio.sleep(delay)
            use_quote = await _should_auto_quote(event, msg, config)
            if use_quote:
                await event.reply(reply)
            else:
                await client.send_message(event.chat_id, reply)
            if event.is_private:
                log_private(f"[trace:{trace_id}] KB_ONLY_REPLY: {reply}")
            else:
                log_group(f"KB_ONLY_REPLY: {reply}")
            stats['total_replies'] += 1
            stats['success_count'] += 1
            save_stats(stats)
            return
        
        # ç¼–æ’æ¨¡å¼ä¸“ç”¨å˜é‡
        orch_enabled = bool(config.get('CONV_ORCHESTRATION', False))
        model_override = AI_MODEL_NAME
        temp_override = config.get('AI_TEMPERATURE', 0.7)
        base_ai_client = get_ai_client()
        ai_client_orch = base_ai_client
        decision = {}

        if orch_enabled:
            try:
                tenant_id = "default"
                mgr = ConversationStateManager(tenant_id)
                state = mgr.get_state("tg", str(event.chat_id))
                
                # 2. STATE_LOADED
                log_trace_event(trace_id, "STATE_LOADED", {"state": state})
                
                # --- 1. Supervisor Decision (State Machine) ---
                sup = SupervisorAgent(tenant_id, config)
                decision = await sup.decide(state, history, base_ai_client, AI_MODEL_NAME)
                
                # 3. SUPERVISOR_DECIDED
                log_trace_event(trace_id, "SUPERVISOR_DECIDED", {
                    "decision": {
                        "current_stage": decision.get("current_stage"),
                        "advance_stage": decision.get("advance_stage"),
                        "next_stage": decision.get("next_stage"),
                        "persona_id": decision.get("persona_id"),
                        "agent_profile_id": decision.get("agent_profile_id"),
                        "need_human": decision.get("need_human"),
                        "override": decision.get("override", False)
                    }
                })
                
                # State Updates Logic
                old_stage = state.get("current_stage")
                if bool(decision.get("advance_stage")):
                    state["current_stage"] = decision.get("next_stage", state.get("current_stage"))
                state["persona_id"] = decision.get("persona_id", state.get("persona_id"))
                state["handoff_required"] = bool(decision.get("need_human", False))
                if "updated_slots" in decision:
                    state["slots"] = decision["updated_slots"]
                
                # 8. STATE_UPDATED (Pre-emptive logging before DB write)
                log_trace_event(trace_id, "STATE_UPDATED", {
                    "before": {"stage": old_stage},
                    "after": {"stage": state.get("current_stage")}
                })

                # Update State in DB
                mgr.update_state("tg", str(event.chat_id), state)
                
                # --- 2. Handoff Check ---
                if state["handoff_required"]:
                    # ... (Handoff logging logic kept simple for brevity) ...
                    conv_mode = config.get('CONVERSATION_MODE', 'ai_visible')
                    handoff_msg = get_mode_specific_response(conv_mode, 'handoff')
                    await event.reply(handoff_msg)
                    return

                # --- 3. Stage Agent Execution ---
                # 4. KB_RETRIEVED (Stage Scope Filtering)
                current_stage = state.get("current_stage", "S0")
                # Filter KB items that have the current stage tag OR are global (no tags or 'all')
                filtered_kb = []
                for it in kb_items:
                    tags = it.get("tags") or []
                    # Allow Global (empty tags or 'all'/'global') OR specific stage match
                    if (not tags) or ("all" in tags) or ("global" in tags) or (current_stage in tags):
                        filtered_kb.append(it)
                
                kb_hits = retrieve_kb_context(msg, filtered_kb, topn=2)
                
                log_trace_event(trace_id, "KB_RETRIEVED", {
                    "stage_scope": [current_stage],
                    "hits": [{"kb_id": it.get("id"), "tags": it.get("tags")} for it in kb_hits]
                })
                qa_only_enabled, qa_reason = detect_qa_only(msg, kb_hits)
                if qa_only_enabled and kb_hits:
                    kb_hits = kb_hits[:1]
                    log_trace_event(trace_id, "QA_ONLY", {"enabled": True, "reason": qa_reason})

                stager = StageAgentRuntime(tenant_id)
                rdec = stager.route_decision(state, history, filtered_kb) # Use filtered KB
                
                http_client2 = httpx.AsyncClient(verify=_ssl_verify_default(), timeout=30.0)
                ai_client_orch = AsyncOpenAI(
                    api_key=AI_API_KEY,
                    base_url=rdec.get("base_url") or AI_BASE_URL,
                    http_client=http_client2
                )
                model_override = rdec.get("model") or AI_MODEL_NAME
                temp_override = float(rdec.get("temperature") or config.get('AI_TEMPERATURE', 0.7))
                
                # 5. STAGE_AGENT_GENERATED
                log_trace_event(trace_id, "STAGE_AGENT_GENERATED", {
                    "used": {
                        "agent_profile_id": decision.get("agent_profile_id"),
                        "model": model_override,
                        "temperature": temp_override,
                        "fallback_used": False
                    },
                    "prompt_meta": {
                        "stage": current_stage,
                        "persona_id": state.get("persona_id"),
                        "kb_hit_ids": [it.get("id") for it in kb_hits]
                    }
                })

                full_system_prompt = stager.build_system_prompt(state, system_prompt, kb_hits) # Use hits
                
                # Record Decision for Audit (DB)
                try:
                    from database import db as _db
                    input_summary = f"User: {msg[:100]}..." 
                    if history:
                        last_ctx = history[-1]['content'][:50] if history else ""
                        input_summary += f" | Prev: {last_ctx}..."

                    _db.record_routing_decision(tenant_id, "tg", str(event.chat_id), {
                        "stage": state.get("current_stage"),
                        "persona": state.get("persona_id"),
                        "agent_profile_id": decision.get("agent_profile_id"),
                        "model": model_override,
                        "base_url": rdec.get("base_url"),
                        "temperature": temp_override,
                        "context": rdec.get("context"),
                        "matched_rule": rdec.get("matched_rule"),
                        "supervisor_decision": decision,
                        "input_summary": input_summary,
                        "manual_intervention": False
                    })
                except Exception:
                    pass
                    
                system_with_kb = full_system_prompt
            except Exception as e:
                log_system(f"âš ï¸ ç¼–æ’é€»è¾‘æ‰§è¡Œå¤±è´¥ (Fallback to Default): {e}")
                log_trace_event(trace_id, "ORCHESTRATION_ERROR", {"error": str(e)})

        # Fallback to standard logic if not orch enabled or failed (system_with_kb prepared)
        if not orch_enabled and not kb_context:
             kb_hits = retrieve_kb_context(msg, kb_items, topn=2)
             qa_only_enabled, qa_reason = detect_qa_only(msg, kb_hits)
             if qa_only_enabled and kb_hits:
                 kb_hits = kb_hits[:1]
                 log_trace_event(trace_id, "QA_ONLY", {"enabled": True, "reason": qa_reason})
                 if kb_hits:
                    parts = []
                    for it in kb_hits:
                        title = it.get("title","")
                        snippet = (it.get("content","") or "")
                        if len(snippet) > 800: snippet = snippet[:800]
                        parts.append(f"[{title}]\n{snippet}")
                    kb_context = "\n\n".join(parts)
                    system_with_kb = system_prompt + "\n\nã€çŸ¥è¯†åº“å‚è€ƒã€‘\n" + kb_context

        messages = [{"role": "system", "content": system_with_kb}]
        
        # Inject Conversation Mode Guidance
        conv_mode = config.get('CONVERSATION_MODE', 'ai_visible')
        conv_guidance = build_conversation_mode_guidance(conv_mode)
        if conv_guidance:
             messages.append({"role": "system", "content": conv_guidance})

        if 'qa_only_enabled' in locals() and qa_only_enabled:
            messages.append({"role": "system", "content": build_qa_only_guidance()})
        messages = messages + history + [{"role": "user", "content": msg}]

        try:
            if event.is_private:
                log_private(f"[trace:{trace_id}] ğŸ¤– AI æ­£åœ¨æ€è€ƒ...")
            else:
                log_group("ğŸ¤– AI æ­£åœ¨æ€è€ƒ...")
            
            # ğŸ” è‡ªåŠ¨é‡è¯•é€»è¾‘ (å¤„ç† SSL è¿æ¥é”™è¯¯)
            gen_result = None
            for attempt in range(2):
                try:
                    # é‡æ–°è·å– client (ç¡®ä¿é‡è¯•æ—¶ä½¿ç”¨æ–°é…ç½®)
                    # æ³¨æ„ï¼šå¦‚æœåŸæœ¬æ˜¯ç¼–æ’æ¨¡å¼ä¸”ä½¿ç”¨äº†è‡ªå®šä¹‰ URLï¼Œè¿™é‡Œä¼šå›é€€åˆ°é»˜è®¤ AI_BASE_URLï¼Œ
                    # ä½†ä½œä¸ºè¿æ¥å¤±è´¥çš„å…œåº•ï¼Œè¿™æ˜¯å¯ä»¥æ¥å—çš„ã€‚
                    current_client = get_ai_client() if attempt > 0 else ai_client_orch
                    
                    audit_manager = AuditManager(current_client, model_override, load_config, platform="telegram")
                    
                    # 6. STYLE_GUARD / AUDIT (Implied)
                    gen_result = await audit_manager.generate_with_audit(
                        messages=messages,
                        user_input=msg,
                        history=history,
                        temperature=temp_override
                    )
                    break # Success
                except APIConnectionError as e:
                    if attempt == 0 and _ssl_verify_default():
                        log_system(f"âš ï¸ [å¸¸è§„å›å¤] è¿æ¥å¤±è´¥: {e}ã€‚æ­£åœ¨å°è¯•å…³é—­ SSL éªŒè¯å¹¶é‡è¯•...")
                        os.environ["HTTPX_VERIFY_SSL"] = "false"
                        reset_ai_client()
                        continue
                    else:
                        raise e 
                except Exception:
                    raise
            
            status_block = {}
            if isinstance(gen_result, dict):
                status_block = gen_result.get("status", {}) or {}
            # Emit STYLE_GUARD event regardless of return shape
            sg_applied = False
            if isinstance(gen_result, dict):
                sg_applied = bool(status_block.get("style_guard_applied"))
            log_trace_event(trace_id, "STYLE_GUARD", {"applied": sg_applied})
            if orch_enabled or status_block:
                if "audit_primary_passed" in status_block:
                    log_trace_event(trace_id, "AUDIT_PRIMARY", {"passed": bool(status_block.get("audit_primary_passed"))})
                if "audit_secondary_passed" in status_block:
                    log_trace_event(trace_id, "AUDIT_SECONDARY", {"passed": bool(status_block.get("audit_secondary_passed"))})
                if "final_action" in status_block:
                    log_trace_event(trace_id, "FINAL_ACTION", {"action": str(status_block.get("final_action"))})

            # Handle new return format (dict) or old (str)
            if isinstance(gen_result, dict):
                reply = gen_result.get("content", "")
                gen_usage = gen_result.get("usage", {})
            else:
                reply = gen_result
                gen_usage = {}
            
            # Aggregate Usage
            total_tokens = gen_usage.get("total_tokens", 0)
            final_model = gen_usage.get("model", model_override)
            
            if 'decision' in locals() and decision:
                 sup_usage = decision.get("usage")
                 if isinstance(sup_usage, dict):
                     total_tokens += sup_usage.get("total_tokens", 0)
                 elif isinstance(sup_usage, int): 
                     total_tokens += sup_usage

            # Simple Cost Estimation
            est_cost = (total_tokens / 1000.0) * 0.002
            
            # Record Message Event to DB
            try:
                current_stage = None
                if 'state' in locals() and state:
                    current_stage = state.get("current_stage")

                db.record_message_event(
                    tenant_id="default",
                    platform="telegram",
                    chat_id=str(event.chat_id),
                    direction="outbound",
                    status="sent",
                    tokens_used=total_tokens,
                    model=final_model,
                    cost=est_cost,
                    stage=current_stage,
                    user_content=msg,
                    bot_response=reply
                )
            except Exception as e:
                log_system(f"âš ï¸ Failed to record message event: {e}")

            if 'qa_only_enabled' in locals() and qa_only_enabled:
                reply = enforce_qa_only(reply, msg)
            dmin = float(config.get('REPLY_DELAY_MIN_SECONDS', 3.0))
            dmax = float(config.get('REPLY_DELAY_MAX_SECONDS', 10.0))
            if dmin > dmax:
                dmin, dmax = dmax, dmin
            delay = random.uniform(dmin, dmax)
            await asyncio.sleep(delay)
            
            use_quote = await _should_auto_quote(event, msg, config)
            if use_quote:
                await event.reply(reply)
            else:
                await client.send_message(event.chat_id, reply)
            
            if event.is_private:
                log_private(f"[trace:{trace_id}] AI_REPLY: {reply}")
            else:
                log_group(f"AI_REPLY: {reply}")
            
            if orch_enabled:
                log_trace_event(trace_id, "REPLY_SENT", {"content_len": len(reply)})
            
            # ç»Ÿè®¡æˆåŠŸå›å¤
            stats['total_replies'] += 1
            stats['success_count'] += 1
            save_stats(stats)
            
        except Exception as e:
            log_system(f"âŒ AI è°ƒç”¨å¤±è´¥: {e}")
            if orch_enabled:
                 log_trace_event(trace_id, "ERROR", {"message": str(e)})
            # ç»Ÿè®¡å¤±è´¥
            stats['error_count'] += 1
            save_stats(stats)

# --- 5. å¯åŠ¨ç¨‹åº ---
if __name__ == '__main__':
    log_system("ğŸš€ ç¨‹åºå¯åŠ¨ä¸­...")
    if _ssl_verify_default():
         log_system("âš ï¸ [é…ç½®è­¦å‘Š] SSLéªŒè¯å·²å¼€å¯ (HTTPX_VERIFY_SSL != false)ã€‚")
         log_system("   å¦‚æœé‡åˆ°è¿æ¥é”™è¯¯ï¼Œè¯·åœ¨ .env ä¸­è®¾ç½®: HTTPX_VERIFY_SSL=false")
    client.start()
    client.run_until_disconnected()
